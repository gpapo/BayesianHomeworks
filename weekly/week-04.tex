\chapter{Monte Carlo simulations}

\section{Exercise 1}

\subsection{Data}

\begin{itemize}
 \item Data sequence: \\
       \texttt{c(1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0)}
\end{itemize}

\subsection{Questions}

Check that the sequence comes from an exchangeable process using the Bayesian
p-value and the number of switch as statistic test.

\subsection{Solutions}

Solution: $ 0.016 $ \\
Code:
\begin{minted}[fontsize=\footnotesize]{R}
set.seed(10)

count_switch <- function(x) x %>% diff() %>% abs() %>% sum()

y <- c(1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0)
t_obs <- sum(abs(diff(y)))

# posterior hyperparameters
alpha <- 0.5 + sum(y)
beta  <- 0.5 + length(y) - sum(y)

niter <- 10000
ssize <- 20

theta <- rbeta(niter, alpha, beta)
t_rep <- map_dbl(theta, ~ rbinom(ssize, 1, .) %>% count_switch())

# Result
pval <- mean(t_rep <= t_obs)
cat("Bayesian p-val:", pval)
\end{minted}

\section{Exercise 2}

\subsection{Questions}

We want a sample from a distribution $ f(x) $ using another distribution $ g(x)
$ through an AR algorithm. Being assumed the value of $ M $, proof that this
algorithm is equivalent to a \textit{standard} AR.
\begin{enumerate}[label=\alph*)]
 \item Generate $ x \sim \text{G} $ \label{AR:step1}
 \item Generate $ u \sim \text{U}(0, M g(x)) $ \label{AR:step2}
 \item Accept $ y \overset{def}{=} x $ if $ u < f(x) $ \label{AR:step3}
 \item Otherwise go back to \ref{AR:step1}.
\end{enumerate}

\subsection{Solutions}

We can see that the two algorithms differ only for steps \ref{AR:step2} and
\ref{AR:step3}, where the difference is the Uniform distribution from which we
sample $ u $. To verify that they are equivalent we have to see if:
\begin{enumerate}
 \item The proportion of values accepted near a generic $ x $ is the same, that
       is equal to $ \frac{f(x)}{M g(x)} $, \label{AR:cond1}
 \item The efficiency is the same: the mean number of replications before
       rejecting a point is the same and it's equal to $ M $. \label{AR:cond2}
\end{enumerate}
In a generic $ u $ in the support of $ \text{U}(0, M g(x)) $ the proportion of
values below $ u $ is
\[ \prob(U < u) = \frac{u}{M g(x)} \]
therefor if $ u \overset{def}{=} f(x) $ the proportion of accepted values given
$ x $ is $ \frac{f(x)}{M g(x)} $, so \ref{AR:cond1} is verified.

Let $ K $ be the number of replications before accepting a value. So
\[ K \sim \text{Geom}(p) \text{ with $ p $ probability of accepting at each replication} \]
We can compute the expected value of acceptance probability:
\[ p = \prob(U \le f(x)) = \int_{S_X} g(x) \int_{0}^{f(x)} \frac{1}{M g(x)} \partial u \partial x = 
   \int_{S_X} g(x) \frac{f(x)}{M g(x)} \partial x = \frac{1}{M} \int_{S_X} f(x) \partial x = \frac{1}{M} \]
So the expected value $ \E[K] = \frac{1}{p} = M $ and even \ref{AR:cond2} is
verified, and we can affirm that the two procedures are equivalent.